{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tempfile\n",
    "\n",
    "input_shape = [20]\n",
    "x_train = np.random.randn(1, 20).astype(np.float32)\n",
    "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=20)\n",
    "\n",
    "def setup_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(20, input_shape=input_shape),\n",
    "      tf.keras.layers.Flatten()\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "def setup_pretrained_weights():\n",
    "  model = setup_model()\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.categorical_crossentropy,\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "  model.fit(x_train, y_train)\n",
    "  _, pretrained_weights = tempfile.mkstemp('.tf')\n",
    "  model.save_weights(pretrained_weights)\n",
    "\n",
    "  return pretrained_weights\n",
    "\n",
    "def get_gzipped_model_size(model):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, keras_file = tempfile.mkstemp('.h5')\n",
    "  model.save(keras_file, include_optimizer=False)\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "# setup\n",
    "setup_model()\n",
    "pretrained_weights = setup_pretrained_weights()\n",
    "print(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define model'''\n",
    "# 修剪整个模型（顺序和功能）\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
    "model_for_pruning_all = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "model_for_pruning_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修剪一些层（顺序层和功能层）\n",
    "# 与从头开始训练相比，通常最好通过修剪来进行微调。\n",
    "# 尝试修剪后几层而不是前几层。\n",
    "# 避免修剪关键层（例如注意机制）。\n",
    "\n",
    "# Helper function uses `prune_low_magnitude` to make only the \n",
    "# Dense layers train with pruning. 仅修剪Dense图层。\n",
    "def apply_pruning_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning_some = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "model_for_pruning_some.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train model'''"
   ]
  }
 ]
}