{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tempfile\n",
    "\n",
    "input_shape = [20]\n",
    "x_train = np.random.randn(1, 20).astype(np.float32)\n",
    "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=20)\n",
    "\n",
    "def setup_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(20, input_shape=input_shape),\n",
    "      tf.keras.layers.Flatten()\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "def setup_pretrained_weights():\n",
    "  model = setup_model()\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.categorical_crossentropy,\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "  model.fit(x_train, y_train)\n",
    "  _, pretrained_weights = tempfile.mkstemp('.tf')\n",
    "  model.save_weights(pretrained_weights)\n",
    "\n",
    "  return pretrained_weights\n",
    "\n",
    "def get_gzipped_model_size(model):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, keras_file = tempfile.mkstemp('.h5')\n",
    "  model.save(keras_file, include_optimizer=False)\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "# setup\n",
    "setup_model()\n",
    "pretrained_weights = setup_pretrained_weights()\n",
    "print(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define model'''\n",
    "# 修剪整个模型（顺序和功能）\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights) # optional but recommended.\n",
    "model_for_pruning_all = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "model_for_pruning_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修剪一些层（顺序层和功能层）\n",
    "# 与从头开始训练相比，通常最好通过修剪来进行微调。\n",
    "# 尝试修剪后几层而不是前几层。\n",
    "# 避免修剪关键层（例如注意机制）。\n",
    "\n",
    "# Helper function uses `prune_low_magnitude` to make only the \n",
    "# Dense layers train with pruning. 仅修剪Dense图层。\n",
    "def apply_pruning_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning_some = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "model_for_pruning_some.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train model'''\n",
    "# Define the model.\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),   \n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "    # 可选项作为超参数\n",
    "]\n",
    "\n",
    "model_for_pruning.compile(\n",
    "      loss=tf.keras.losses.categorical_crossentropy,\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_for_pruning.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    callbacks=callbacks,\n",
    "    epochs=2,\n",
    ")\n",
    "model_for_pruning.summary()\n",
    "\n",
    "_, keras_model_file = tempfile.mkstemp('.h5')\n",
    "print(keras_model_file)\n",
    "# Checkpoint: saving the optimizer is necessary (include_optimizer=True is the default).\n",
    "model_for_pruning.save(keras_model_file, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize model. 反序列化模型\n",
    "with tfmot.sparsity.keras.prune_scope():\n",
    "  loaded_model = tf.keras.models.load_model(keras_model_file)\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model.\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights) # optional but recommended for model accuracy\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "# strip_pruning应用标准压缩算法（例如通过gzip）\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning) \n",
    "print(\"final model\")\n",
    "model_for_export.summary()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Size of gzipped pruned model without stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_pruning)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_export)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增大块大小将降低目标模型精度可达到的峰值稀疏性\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights) \n",
    "# For using intrinsics on a CPU with 128-bit registers, together with 8-bit\n",
    "# quantized weights, a 1x16 block size is nice because the block perfectly\n",
    "# fits into the register.\n",
    "pruning_params = {'block_size': [1, 16]}\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  }
 ]
}