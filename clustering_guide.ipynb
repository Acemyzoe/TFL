{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "input_dim = 20\n",
    "output_dim = 20\n",
    "x_train = np.random.randn(1, input_dim).astype(np.float32)\n",
    "y_train = tf.keras.utils.to_categorical(np.random.randn(1), num_classes=output_dim)\n",
    "\n",
    "def setup_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(input_dim, input_shape=[input_dim]),\n",
    "      tf.keras.layers.Flatten()\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "def train_model(model):\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.categorical_crossentropy,\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "  model.summary()\n",
    "  model.fit(x_train, y_train)\n",
    "  return model\n",
    "\n",
    "def save_model_weights(model):\n",
    "  _, pretrained_weights = tempfile.mkstemp('.h5')\n",
    "  model.save_weights(pretrained_weights)\n",
    "  return pretrained_weights\n",
    "\n",
    "def setup_pretrained_weights():\n",
    "  model= setup_model()\n",
    "  model = train_model(model)\n",
    "  pretrained_weights = save_model_weights(model)\n",
    "  return pretrained_weights\n",
    "\n",
    "def setup_pretrained_model():\n",
    "  model = setup_model()\n",
    "  pretrained_weights = setup_pretrained_weights()\n",
    "  model.load_weights(pretrained_weights)\n",
    "  return model\n",
    "\n",
    "def save_model_file(model):\n",
    "  _, keras_file = tempfile.mkstemp('.h5') \n",
    "  model.save(keras_file, include_optimizer=False)\n",
    "  return keras_file\n",
    "\n",
    "def get_gzipped_model_size(model):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  keras_file = save_model_file(model)\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(keras_file)\n",
    "  return os.path.getsize(zipped_file)\n",
    "\n",
    "setup_model()\n",
    "pretrained_weights = setup_pretrained_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚类整个模型\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 3,\n",
    "  'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.DENSITY_BASED\n",
    "}\n",
    "\n",
    "model = setup_model()\n",
    "model.load_weights(pretrained_weights)\n",
    "clustered_model = tfmot.clustering.keras.cluster_weights(model, **clustering_params)\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集群一些层（顺序模型和功能模型）\n",
    "# Create a base model\n",
    "base_model = setup_model()\n",
    "base_model.load_weights(pretrained_weights)\n",
    "\n",
    "# Helper function uses `cluster_weights` to make only \n",
    "# the Dense layers train with clustering\n",
    "def apply_clustering_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return cluster_weights(layer, **clustering_params)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_clustering_to_dense` \n",
    "# to the layers of the model.\n",
    "clustered_model = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_clustering_to_dense,\n",
    ")\n",
    "\n",
    "# Save or checkpoint the model.\n",
    "_, keras_model_file = tempfile.mkstemp('.h5')\n",
    "clustered_model.save(keras_model_file, include_optimizer=True)\n",
    "print(keras_model_file)\n",
    "\n",
    "# `cluster_scope` is needed for deserializing HDF5 models.\n",
    "with tfmot.clustering.keras.cluster_scope():\n",
    "  loaded_model = tf.keras.models.load_model(keras_model_file)\n",
    "\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用标准压缩算法\n",
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "final_model.summary()\n",
    "\n",
    "print(\"Size of gzipped clustered model without stripping: %.2f bytes\" \n",
    "      % (get_gzipped_model_size(clustered_model)))\n",
    "print(\"Size of gzipped clustered model with stripping: %.2f bytes\" \n",
    "      % (get_gzipped_model_size(final_model)))"
   ]
  }
 ]
}